Another aspect of data cleaning is transmuting data, which calls for standardising data types and normalising numerical values. This process promotes a unified data structure ideal for insightful analysis. To prevent distortion and retain the integrity of analysis, outliers are carefully identified and handled. This preserves the integrity of the dataset.
Data integrity checks are carried out to validate categorical variables and remove discrepancies in the pursuit of data accuracy. By carefully addressing typos and inconsistencies, data consistency and clarity are elevated to the fore. The dataset is streamlined for best use by eliminating extraneous attributes that add little to the analytical process.
In all the dataframes there are duplicate values which has been treated and there are also null values which has been removed from each of the dataframes. The unnecessary columns have been removed from all the dataframes for robust analysis. Dataframes should be properly formatted with the proper format so that all dataframes should be get synchronized. As our data is a time series data, we must make sure that the data is properly index and sorted with respect to date time column, also there should be no missing timestamps if there are these should be treated accordingly.

To do the same, first the format of the columns has been checked and changed to proper format for example: the date time column has been fixed to the datetime format ("%d/%m/%Y %H: %M"). The data of each of the hospitals are stored in the separate dataframes and then for each of the dataframe separated dataframe the date time column had been set as index and then checked whether it contains any duplicate index or not. After this check the data has been resampled. To resample the datetime index the data has been looked closely and according to the minimum frequency which is the frequency at which the data is collected from the online dashboard. The resampled data has filled with NA values so that when we visualise the data then missing timestamps should be highlighted. Each of the dataframes that were broken down with respect to hospitals are then concatenated to get the data of all the hospitals in the single dataframe. This gives a clear picture about the data and help us to understand the data better. For carrying out the time series analysis these null values can be filled using forward fill, backward fill or may be interpolation. The values should be filled such that the represented data looks well-structured real.
